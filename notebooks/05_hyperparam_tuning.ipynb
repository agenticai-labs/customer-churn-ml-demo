{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b7bf6fa",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "\n",
    "### Purpose:\n",
    "Import essential libraries for data processing, hyperparameter tuning, and model persistence.\n",
    "\n",
    "### Libraries Used:\n",
    "- **pandas**: Data manipulation\n",
    "- **sklearn.model_selection**: Train/test split and GridSearchCV for hyperparameter tuning\n",
    "- **sklearn.ensemble**: Random Forest classifier\n",
    "- **sklearn.metrics**: Model evaluation metrics\n",
    "- **joblib**: Efficient model serialization (saving/loading)\n",
    "- **os**: File system operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6940381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d73eb56",
   "metadata": {},
   "source": [
    "## 2. Setup Model Directory\n",
    "\n",
    "### Purpose:\n",
    "Create a directory to store the trained model file.\n",
    "\n",
    "### Key Details:\n",
    "- **exist_ok=True**: Prevents error if directory already exists\n",
    "- Ensures organized file structure for model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d718a53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Models directory ready\n"
     ]
    }
   ],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "print(\"✓ Models directory ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fce28e",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Data\n",
    "\n",
    "### Purpose:\n",
    "Load the featured dataset and prepare it for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed992a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 100 customers, 57 features\n",
      "Churn rate: 44.00%\n"
     ]
    }
   ],
   "source": [
    "# Load featured data\n",
    "df = pd.read_csv('../data/customer_churn_featured.csv')\n",
    "\n",
    "# Prepare features and target\n",
    "X = df.drop(['customer_id', 'churned'], axis=1)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = df['churned']\n",
    "\n",
    "print(f\"Dataset loaded: {df.shape[0]} customers, {X.shape[1]} features\")\n",
    "print(f\"Churn rate: {y.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ff2e4b",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "- Confirms data is loaded successfully\n",
    "- Shows total number of features after one-hot encoding\n",
    "- Displays overall churn rate in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e60b1b",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split\n",
    "\n",
    "### Purpose:\n",
    "Divide data into training (80%) and testing (20%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "630b61cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 80\n",
      "Test samples: 20\n",
      "Number of features: 57\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88361ab",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "- Training set will be used for grid search and cross-validation\n",
    "- Test set remains completely unseen until final evaluation\n",
    "- Ensures unbiased performance assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018eff9f",
   "metadata": {},
   "source": [
    "## 5. Define Parameter Grid\n",
    "\n",
    "### Purpose:\n",
    "Specify the hyperparameter values to test in grid search.\n",
    "\n",
    "### Hyperparameters Explained:\n",
    "\n",
    "#### **n_estimators** (Number of Trees)\n",
    "- **50**: Faster training, may underfit\n",
    "- **100**: Good balance (default)\n",
    "- **200**: More accurate but slower\n",
    "\n",
    "#### **max_depth** (Tree Depth)\n",
    "- **5**: Shallow trees, prevents overfitting but may underfit\n",
    "- **10**: Moderate depth, good starting point\n",
    "- **15**: Deep trees, captures complex patterns but risk of overfitting\n",
    "- **None** (not tested here): Unlimited depth until leaves are pure\n",
    "\n",
    "#### **min_samples_split** (Minimum Samples to Split)\n",
    "- **2**: Very sensitive, creates detailed trees (more overfitting risk)\n",
    "- **5**: Balanced approach\n",
    "- **10**: Conservative, creates simpler trees (more regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9673aa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Grid:\n",
      "  n_estimators: [50, 100, 200]\n",
      "  max_depth: [5, 10, 15]\n",
      "  min_samples_split: [2, 5, 10]\n",
      "\n",
      "Total combinations to test: 27\n",
      "With 5-fold CV: 135 total model fits\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "total_combinations = (len(param_grid['n_estimators']) * \n",
    "                     len(param_grid['max_depth']) * \n",
    "                     len(param_grid['min_samples_split']))\n",
    "\n",
    "print(\"Parameter Grid:\")\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "print(f\"\\nTotal combinations to test: {total_combinations}\")\n",
    "print(f\"With 5-fold CV: {total_combinations * 5} total model fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e438e4",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "- Grid search will train and evaluate 27 different parameter combinations\n",
    "- Each combination is tested 5 times (cross-validation folds)\n",
    "- Total: 135 model training iterations\n",
    "- This ensures robust evaluation of each configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2562c9b",
   "metadata": {},
   "source": [
    "## 6. Perform Grid Search with Cross-Validation\n",
    "\n",
    "### Purpose:\n",
    "Systematically test all hyperparameter combinations using 5-fold cross-validation to find the optimal configuration.\n",
    "\n",
    "### How Grid Search Works:\n",
    "1. **For each parameter combination**:\n",
    "   - Split training data into 5 folds\n",
    "   - Train on 4 folds, validate on 1 fold\n",
    "   - Repeat 5 times (each fold used as validation once)\n",
    "   - Average the 5 validation scores\n",
    "2. **Select best combination**: Highest average CV score\n",
    "\n",
    "### Key Parameters:\n",
    "- **cv=5**: 5-fold cross-validation\n",
    "- **scoring='accuracy'**: Optimization metric\n",
    "- **n_jobs=-1**: Use all CPU cores for parallel processing\n",
    "- **verbose=1**: Print progress updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6931f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HYPERPARAMETER TUNING WITH GRID SEARCH\n",
      "================================================================================\n",
      "Starting grid search...\n",
      "\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "\n",
      "================================================================================\n",
      "GRID SEARCH COMPLETE\n",
      "================================================================================\n",
      "✓ Best parameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "✓ Best cross-validation score: 1.0000\n",
      "\n",
      "================================================================================\n",
      "GRID SEARCH COMPLETE\n",
      "================================================================================\n",
      "✓ Best parameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "✓ Best cross-validation score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"HYPERPARAMETER TUNING WITH GRID SEARCH\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Starting grid search...\\n\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42), \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search (this will take some time)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GRID SEARCH COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"✓ Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"✓ Best cross-validation score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c838fa",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "- **Best parameters**: The optimal hyperparameter combination found\n",
    "- **Best CV score**: Average accuracy across 5 folds for the best configuration\n",
    "- **Example interpretation**:\n",
    "  - If best_params = {n_estimators: 200, max_depth: 10, min_samples_split: 5}\n",
    "  - Means: 200 trees with moderate depth and moderate split threshold performed best\n",
    "  - If CV score = 0.8542, the model achieves ~85.4% accuracy on average across folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17029239",
   "metadata": {},
   "source": [
    "## 7. Analyze Grid Search Results\n",
    "\n",
    "### Purpose:\n",
    "Examine all tested combinations to understand how different hyperparameters affect performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba989956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Parameter Combinations:\n",
      "================================================================================\n",
      " param_n_estimators  param_max_depth  param_min_samples_split  mean_test_score  std_test_score  rank_test_score\n",
      "                 50                5                        2              1.0             0.0                1\n",
      "                 50               15                       10              1.0             0.0                1\n",
      "                200               15                        5              1.0             0.0                1\n",
      "                100               15                        5              1.0             0.0                1\n",
      "                 50               15                        5              1.0             0.0                1\n",
      "                200               15                        2              1.0             0.0                1\n",
      "                100               15                        2              1.0             0.0                1\n",
      "                 50               15                        2              1.0             0.0                1\n",
      "                200               10                       10              1.0             0.0                1\n",
      "                100               10                       10              1.0             0.0                1\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with all results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Select and sort relevant columns\n",
    "results_df = cv_results[[\n",
    "    'param_n_estimators', \n",
    "    'param_max_depth', \n",
    "    'param_min_samples_split',\n",
    "    'mean_test_score',\n",
    "    'std_test_score',\n",
    "    'rank_test_score'\n",
    "]].sort_values('rank_test_score')\n",
    "\n",
    "print(\"Top 10 Parameter Combinations:\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1378f417",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "- **mean_test_score**: Average accuracy across 5 folds\n",
    "- **std_test_score**: Standard deviation (lower = more consistent)\n",
    "- **rank_test_score**: 1 = best combination\n",
    "- Look for patterns:\n",
    "  - Do higher n_estimators consistently perform better?\n",
    "  - Is there an optimal max_depth?\n",
    "  - How much does performance vary between top combinations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3767de4b",
   "metadata": {},
   "source": [
    "## 8. Extract and Evaluate Best Model\n",
    "\n",
    "### Purpose:\n",
    "Retrieve the best model and evaluate its performance on the held-out test set.\n",
    "\n",
    "### Why Test Set Evaluation?\n",
    "- Cross-validation scores are based on training data\n",
    "- Test set provides unbiased estimate of real-world performance\n",
    "- Checks if the model generalizes beyond data used in hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae207fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST SET PERFORMANCE\n",
      "================================================================================\n",
      "Test Accuracy: 1.0000\n",
      "\n",
      "Comparison:\n",
      "  Best CV Score (training): 1.0000\n",
      "  Test Score (unseen data): 1.0000\n",
      "  Difference: 0.0000\n",
      "\n",
      "================================================================================\n",
      "CLASSIFICATION REPORT\n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Churned       1.00      1.00      1.00        11\n",
      "     Churned       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST SET PERFORMANCE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Best CV Score (training): {grid_search.best_score_:.4f}\")\n",
    "print(f\"  Test Score (unseen data): {test_accuracy:.4f}\")\n",
    "print(f\"  Difference: {abs(grid_search.best_score_ - test_accuracy):.4f}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_report(y_test, y_pred, target_names=['Not Churned', 'Churned']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c5b075",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "\n",
    "#### **CV Score vs Test Score Comparison**:\n",
    "- **Small difference (< 2%)**: Good generalization, model is robust\n",
    "- **Test score lower by 3-5%**: Acceptable, slight overfitting\n",
    "- **Test score lower by > 5%**: Significant overfitting, consider:\n",
    "  - More regularization (higher min_samples_split, lower max_depth)\n",
    "  - More training data\n",
    "  - Feature selection\n",
    "- **Test score higher than CV**: Lucky split or model underfitting training data\n",
    "\n",
    "#### **Classification Report**:\n",
    "- Check if tuning improved metrics compared to baseline model\n",
    "- Focus on recall for churned class (critical for business)\n",
    "- Balanced precision and recall indicate well-calibrated model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb39515d",
   "metadata": {},
   "source": [
    "## 9. Save the Tuned Model\n",
    "\n",
    "### Purpose:\n",
    "Persist the optimized model to disk for deployment and future predictions.\n",
    "\n",
    "### Why joblib?\n",
    "- More efficient than pickle for large numpy arrays\n",
    "- Standard format for scikit-learn models\n",
    "- Enables model versioning and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd4a8b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL SAVED SUCCESSFULLY\n",
      "================================================================================\n",
      "✓ Model saved to: ../models/tuned_churn_model.pkl\n",
      "✓ Best parameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "✓ Test accuracy: 1.0000\n",
      "\n",
      "To load this model later:\n",
      "  loaded_model = joblib.load('../models/tuned_churn_model.pkl')\n",
      "  predictions = loaded_model.predict(new_data)\n"
     ]
    }
   ],
   "source": [
    "# Save the tuned model\n",
    "model_path = '../models/tuned_churn_model.pkl'\n",
    "joblib.dump(best_model, model_path)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL SAVED SUCCESSFULLY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"✓ Model saved to: {model_path}\")\n",
    "print(f\"✓ Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"✓ Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Show how to load the model later\n",
    "print(\"\\nTo load this model later:\")\n",
    "print(f\"  loaded_model = joblib.load('{model_path}')\")\n",
    "print(\"  predictions = loaded_model.predict(new_data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbc1666",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "- Model is now ready for production use\n",
    "- Can be loaded in other scripts for making predictions\n",
    "- Contains all optimized hyperparameters and learned patterns\n",
    "- Should be versioned and tracked in your model registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d471f2c",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "### What We Accomplished:\n",
    "✅ Systematically tested 27 hyperparameter combinations\n",
    "✅ Used 5-fold cross-validation for robust evaluation\n",
    "✅ Identified optimal Random Forest configuration\n",
    "✅ Validated performance on held-out test set\n",
    "✅ Saved production-ready model\n",
    "\n",
    "### Key Takeaways:\n",
    "- Hyperparameter tuning can significantly improve model performance\n",
    "- Grid search ensures we don't miss good configurations\n",
    "- Cross-validation provides reliable performance estimates\n",
    "- Test set validation ensures model generalizes to new data\n",
    "\n",
    "### Next Steps:\n",
    "1. **Feature Analysis**: Examine feature importance from tuned model\n",
    "2. **Error Analysis**: Investigate misclassified cases\n",
    "3. **Model Deployment**: Integrate model into production system\n",
    "4. **Monitoring**: Track model performance on live data\n",
    "5. **Retraining**: Periodically retune with new data\n",
    "\n",
    "### Advanced Tuning Options:\n",
    "- **RandomizedSearchCV**: Sample parameter space (faster for many parameters)\n",
    "- **Bayesian Optimization**: Intelligent search using prior results\n",
    "- **Additional hyperparameters**: min_samples_leaf, max_features, class_weight\n",
    "- **Different scoring metrics**: F1-score, ROC-AUC for imbalanced data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv-python-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
